{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch_geometric.utils import (\n",
    "    dense_to_sparse,\n",
    "    to_dense_adj,\n",
    "    remove_isolated_nodes,\n",
    "    contains_isolated_nodes,\n",
    "    subgraph, k_hop_subgraph\n",
    ")\n",
    "from data_loader import HetGCNEventGraphDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading node features..\n",
      "reading edge index..\n",
      "Ignore Edge Weights.\n",
      "read node types ..\n",
      "node types txt: 132485\n",
      "reading edge ratio ...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "data_root_dir = '../ProcessedData_HetGCN'\n",
    "dataset = HetGCNEventGraphDataset(\n",
    "    node_feature_csv=f'{data_root_dir}/node_feature_norm.csv',\n",
    "    edge_index_csv=f'{data_root_dir}/edge_index.csv',\n",
    "    node_type_txt=f'{data_root_dir}/node_types.txt',\n",
    "    edge_ratio_csv=f'{data_root_dir}/edge_ratio.csv',\n",
    "    ignore_weight=True,\n",
    "    include_edge_type=True,\n",
    "    edge_ratio_percentile=0.75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample graph\n",
    "node_feature, edge_index, (edge_weight, edge_type), node_types = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([841, 7]), torch.Size([2, 962]), (None, torch.Size([962])), 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feature.shape, edge_index.shape, (edge_weight, edge_type.shape), len(node_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains_isolated_nodes(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_node_ratio = 0.01\n",
    "sampled_nodes = random.sample(\n",
    "    range(node_feature.shape[0]),\n",
    "    int(node_feature.shape[0] * sample_node_ratio)\n",
    ")\n",
    "len(sampled_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subgraph(\n",
    "#     subset=sampled_nodes,\n",
    "#     edge_index=edge_index\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([274]), tensor([108]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "row, col = edge_index\n",
    "cond = col == 108\n",
    "row[cond],col[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[138, 138, 179, 179, 181, 181, 245, 245, 482, 482],\n",
       "        [705, 705, 747, 750, 753, 753, 812, 816, 394, 425]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = edge_index.device\n",
    "sub_nodes, sub_edge_index, _, sub_edge_mask  = k_hop_subgraph(\n",
    "    node_idx=sampled_nodes,\n",
    "    num_hops=1,\n",
    "    edge_index=edge_index,\n",
    "    flow='target_to_source'\n",
    ")\n",
    "sub_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[482, 825, 179, 559, 181, 731, 245, 138]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[138, 138, 179, 179, 181, 181, 245, 245, 482, 482],\n",
       "        [888, 888, 888, 888, 888, 888, 888, 888, 888, 888]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_edge_index.index_fill(0, torch.tensor([1], device=device), 888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   2,   2,  ..., 245, 482, 482],\n",
       "        [558, 559, 559,  ..., 888, 888, 888]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row, col == edge_index\n",
    "\n",
    "torch.cat(\n",
    "    [torch.stack([row[~sub_edge_mask], col[~sub_edge_mask]]), sub_edge_index.index_fill(0, torch.tensor([1], device=device), 888)],\n",
    "    dim=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[138, 138, 179, 179, 181, 181, 245, 245, 482, 482],\n",
       "        [705, 705, 747, 750, 753, 753, 812, 816, 394, 425]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip mask\n",
      "skip node type 6\n",
      "skip node type 7\n"
     ]
    }
   ],
   "source": [
    "new_node_list = []\n",
    "last_node_id = node_feature.shape[0] - 1\n",
    "for ntype, ntype_list in enumerate(node_types):\n",
    "    if len(ntype_list) == 0:\n",
    "        print(f'skip node type {ntype}')\n",
    "        continue \n",
    "    _mask = sum(sub_edge_index[1] == i for i in ntype_list).bool()\n",
    "\n",
    "    # skip if no node matched\n",
    "    if _mask.sum() == 0:\n",
    "        print('skip mask')\n",
    "        continue\n",
    "\n",
    "    new_node_id = last_node_id + 1\n",
    "    new_node_list.append((new_node_id, ntype))\n",
    "    sub_edge_index[1] = sub_edge_index[1].masked_fill_(_mask, new_node_id)\n",
    "\n",
    "    last_node_id = new_node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(841, 0), (842, 2), (843, 3), (844, 4), (845, 5)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[138, 138, 179, 179, 181, 181, 245, 245, 482, 482],\n",
       "        [844, 844, 842, 841, 845, 845, 842, 841, 843, 842]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "if _mask.sum() == 1:\n",
    "    print(1)\n",
    "else:\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([705, 705, 747,   1, 753, 753, 812,   1, 394, 425])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_edge_index[1].masked_fill_(_mask, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3552e-04,  2.6773e-04, -1.8384e-05,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  2.6262e-04],\n",
       "        [ 2.3552e-04,  2.6773e-04, -1.8384e-05,  ...,  1.0313e-04,\n",
       "          0.0000e+00,  2.6278e-04],\n",
       "        [ 8.0982e-05,  2.6773e-04, -1.8384e-05,  ...,  2.0626e-04,\n",
       "          0.0000e+00,  7.9132e-05],\n",
       "        ...,\n",
       "        [ 3.8716e-06,  1.2357e-04,  2.3899e-04,  ...,  2.0626e-04,\n",
       "          4.9475e-04,  3.7832e-06],\n",
       "        [ 2.2149e-04,  1.2357e-04,  1.1030e-04,  ...,  2.5782e-04,\n",
       "          4.9622e-04,  2.2116e-04],\n",
       "        [ 2.2149e-04,  1.2357e-04,  1.1030e-04,  ...,  2.5782e-04,\n",
       "          4.9768e-04,  2.2116e-04]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_augmentation import create_het_node_insertion\n",
    "\n",
    "a = create_het_node_insertion([dataset[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 962]), torch.Size([2, 962]), torch.Size([2, 962]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1].shape, edge_index.shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([846, 7]), torch.Size([841, 7]), torch.Size([850, 7]))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape, node_feature.shape, b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0,   2,   2,  ..., 458, 520, 520],\n",
       "         [558, 559, 559,  ..., 843, 844, 843]]),\n",
       " tensor([[  0,   2,   2,  ..., 557, 557, 558],\n",
       "         [558, 559, 559,  ..., 700, 837,  73]]))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1], edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   2,   2,  ..., 557, 557, 558],\n",
       "        [558, 559, 559,  ..., 700, 837,  73]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   2,   2,  ..., 376, 445, 445],\n",
       "        [558, 559, 559,  ..., 846, 849, 848]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([558, 559, 559, 556, 560, 562, 562, 563, 563, 561, 565, 567, 567, 568,\n",
       "        568, 569, 569, 566, 570, 572, 572, 573, 573, 574, 574, 571, 575, 577,\n",
       "        577, 578, 578, 579, 579, 576, 580, 582, 582, 583, 583, 584, 584, 581,\n",
       "        585, 587, 587, 588, 588, 589, 589, 590, 590, 586, 591, 593, 593, 594,\n",
       "        594, 595, 595, 592, 596, 598, 598, 599, 599, 600, 600, 601, 601, 597,\n",
       "        602, 604, 604, 605, 605, 603, 606, 608, 608, 609, 609, 607, 610, 612,\n",
       "        612, 613, 613, 614, 614, 611, 615, 617, 617, 618, 618, 619, 619, 616,\n",
       "        620, 622, 622, 623, 623, 624, 624, 621, 625, 627, 627, 628, 628, 629,\n",
       "        629, 630, 630, 626, 631, 633, 633, 634, 634, 635, 635, 636, 636, 632,\n",
       "        637, 639, 639, 640, 640, 641, 641, 642, 642, 638, 643, 645, 645, 646,\n",
       "        646, 644, 647, 649, 649, 650, 650, 648, 651, 653, 653, 654, 654, 652,\n",
       "        655, 657, 657, 658, 658, 659, 659, 656, 660, 662, 662, 663, 663, 664,\n",
       "        664, 665, 665, 666, 666, 667, 667, 668, 668, 669, 669, 670, 670, 671,\n",
       "        671, 672, 672, 673, 673, 674, 674, 675, 675, 676, 676, 677, 677, 661,\n",
       "        678, 680, 680, 681, 681, 682, 682, 683, 683, 679, 684, 686, 686, 687,\n",
       "        687, 688, 688, 689, 689, 690, 690, 691, 691, 692, 692, 694, 694, 695,\n",
       "        695, 696, 696, 697, 697, 698, 698, 699, 699, 700, 700, 701, 701, 685,\n",
       "        702, 704, 704, 705, 705, 703, 706, 708, 708, 709, 709, 710, 710, 711,\n",
       "        711, 713, 713, 714, 714, 707, 715, 717, 717, 718, 718, 719, 719, 720,\n",
       "        720, 721, 721, 722, 722, 723, 723, 716, 724, 726, 726, 727, 727, 725,\n",
       "        728, 730, 730, 731, 731, 732, 732, 733, 733, 734, 734, 735, 735, 736,\n",
       "        736, 737, 737, 738, 738, 739, 739, 740, 740, 741, 741, 742, 742, 743,\n",
       "        743, 744, 744, 745, 745, 729, 746, 748, 748, 749, 749, 747, 750, 752,\n",
       "        752, 753, 753, 754, 754, 755, 755, 756, 756, 757, 757, 758, 758, 751,\n",
       "        759, 761, 761, 762, 762, 760, 763, 765, 765, 766, 766, 767, 767, 764,\n",
       "        768, 770, 770, 771, 771, 772, 772, 769, 773, 775, 775, 776, 776, 777,\n",
       "        777, 774, 778, 780, 780, 781, 781, 782, 782, 783, 783, 786, 786, 787,\n",
       "        787, 788, 788, 789, 789, 785, 790, 792, 792, 793, 793, 794, 794, 791,\n",
       "        795, 797, 797, 798, 798, 799, 799, 800, 800, 796, 801, 803, 803, 804,\n",
       "        804, 805, 805, 802, 806, 808, 808, 809, 809, 810, 810, 807, 811, 813,\n",
       "        813, 814, 814, 815, 815, 812, 816, 818, 818, 819, 819, 820, 820, 817,\n",
       "        821, 823, 823, 824, 824, 825, 825, 822, 826, 828, 828, 829, 829, 830,\n",
       "        830, 827, 831, 833, 833, 834, 834, 835, 835, 832, 836, 838, 838, 839,\n",
       "        839, 840, 840, 837,   3,  74,  76,  79,  81,  89,  91,  94,  96, 100,\n",
       "         10, 104,  11, 108,  15, 112,  14, 117,  13, 121,  16, 125,  19, 129,\n",
       "        114, 134, 132, 163, 137, 192, 165, 196, 139, 200, 170, 204, 142, 213,\n",
       "        175, 218, 145, 222, 179, 226, 150, 232,  22, 238, 240, 243, 154, 272,\n",
       "        245, 276, 158, 280, 183, 284, 248, 288, 251, 292, 185, 297, 255, 301,\n",
       "        259, 305, 263, 311, 265, 315,  26, 319,  28, 324,  25, 329,  29, 334,\n",
       "         33, 339,  32, 344, 336, 349, 346, 355, 341, 361, 353, 367, 358, 371,\n",
       "        363, 375,  37, 379,  40, 384, 381, 389,  36, 395, 397, 400, 386, 406,\n",
       "        408, 412, 402, 416, 391, 420,  43, 424,  42, 442,  45, 460, 444, 478,\n",
       "        462, 487, 491, 496, 482, 500, 426, 504, 508, 513, 466, 517, 430, 522,\n",
       "        448, 527, 469, 532, 433, 538, 451, 544, 535, 550, 542, 555, 548, 560,\n",
       "        436, 565, 472, 570, 454, 575,  48, 580, 582, 585,  49, 591, 594, 596,\n",
       "        587, 602, 598, 606,  53, 610,  55, 615,  52, 620, 612, 625, 618, 622,\n",
       "        637, 633, 643, 627, 647, 639, 651,  60, 655,  57, 660, 657, 678,  59,\n",
       "        684, 680, 702, 662, 706, 686, 715, 710, 724,  63, 728, 719, 746, 732,\n",
       "        750, 754, 759, 666, 763, 690, 768, 734, 773, 669, 778, 693, 784, 788,\n",
       "        790, 739, 795, 799, 801, 782, 806, 673, 811, 740, 816,  65, 821,  67,\n",
       "        826, 696, 831,  71, 836,  75,   5,  80,  78,  86,  84,  90,   7,  95,\n",
       "         93, 101,  99, 105,  12, 109,  17, 113,  24, 118,  18, 122,  21, 126,\n",
       "         20, 130,  23, 135, 116, 164, 133, 193, 140, 197, 168, 201, 143, 205,\n",
       "        172, 209, 146, 214, 174, 219, 177, 223, 148, 227, 152, 239,  27, 244,\n",
       "        242, 273, 156, 277, 249, 281, 159, 285, 186, 289, 252, 293, 254, 298,\n",
       "        188, 302, 257, 306, 261, 312, 268, 320,  31, 325,  34, 330,  30, 335,\n",
       "         38, 340,  35, 345,  39, 350, 338, 356, 348, 362, 343, 368, 354, 372,\n",
       "        360, 376, 366, 380,  44, 385,  46, 390, 383, 396,  41, 401, 399, 407,\n",
       "        388, 413, 411, 417, 405, 421, 394, 425,  47, 443,  50, 461,  51, 479,\n",
       "        449, 488, 467, 497, 493, 501, 484, 505, 431, 514, 510, 518, 470, 523,\n",
       "        434, 528, 452, 533, 473, 539, 437, 545, 455, 551, 537, 556, 543, 561,\n",
       "        549, 566, 440, 571, 476, 576, 458, 581,  56, 586, 584, 592,  54, 597,\n",
       "        595, 603, 590, 607, 601, 611,  58, 616,  62, 621,  61, 626, 614, 632,\n",
       "        624, 644, 636, 648, 630, 652, 642, 656,  64, 661,  68, 679, 659, 685,\n",
       "         72, 703, 683, 707, 667, 716, 691, 725, 712, 729,  66, 747, 721, 751,\n",
       "        735, 760, 756, 764, 670, 769, 694, 774, 737, 779, 672, 785, 697, 791,\n",
       "        789, 796, 741, 802, 800, 807, 783, 812, 676, 817, 744, 822,  69, 827,\n",
       "         70, 832, 700, 837,  73])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1][1][b[1][1] <= 840]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   2,   2,  ..., 458, 520, 520],\n",
       "        [558, 559, 559,  ..., 843, 844, 843]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd65f12e531413a9916e885ddcda4713ce1e92a965375bff78a972ca39458109"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
